# TeamMacaroni
Our experiment tested the runtime in nanoseconds of large n * n Matrix data sets. We had three trials for each value of n and averaged the results of the three trials to collect more accurate data. The value of n increases at a constant rate of 50 per loop so that we can test whether our data runs in O(n) time or not. While we generally got the linear increase as the data set grows larger, there were surprises in the results. We got repeating spikes in the data whose peaks are at 2700, 4150, 5500, 6650, 7850, 8650, 9150, 9600, 10000. The interesting thing about these peaks is that the difference between peaks is always decreasing from 1450 to 1350 to 1150 and so on. It was especially surprising to see that the peaks at which the average time was the highest were not in any form of an arithmetic/linear progression. However, this is still a linear regression as seen by the general trend line we did on the graph which means that our function definitely runs in O(n) time.
